{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 爬取链家数据,将房源的关注度做成热力图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml import etree\n",
    "import requests\n",
    "import re\n",
    "import json\n",
    "from urllib.request import urlopen, quote\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://nj.lianjia.com/ershoufang/pg\"#url地址，根据页码数或有变化\n",
    "headers = {'Referer':'http://www.baidu.com',\\\n",
    "           'User-Agent':'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36'}\n",
    "N = 100#网页的页数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "#存放房源信息，可用csv.DictWriter函数将内容写入csv文件\n",
    "house = {\\\n",
    "        'name':'',\n",
    "        'loc':'',\n",
    "        'style':'',\n",
    "        'size':'',\n",
    "        'price':'',\n",
    "        'foc':''\n",
    "        }\n",
    "\n",
    "\"\"\"\n",
    "  在百度开发者平台上http://lbsyun.baidu.com/，注册，然后申请密匙，应用名称可以随便填，应用类型选择浏览器端即可。\n",
    "  百度地图根据名称查询地点的经纬度的教程可以参考 这篇博客http://blog.csdn.net/qq_23926575/article/details/72569995\n",
    "\"\"\"\n",
    "\n",
    "def getlocation(name):#调用百度API查询位置\n",
    "    bdurl = 'http://api.map.baidu.com/geocoder/v2/?address='\n",
    "    output = 'json'\n",
    "    ak = 'IluUW18NKIHMhOgjm0FHNFdh91q91U60'#输入你刚才申请的密匙\n",
    "    callback = 'showLocation'\n",
    "    uri = bdurl+name+'&output=t'+output+'&ak='+ak+'&callback='+callback\n",
    "    res = requests.get(uri,headers=headers)\n",
    "    s = BeautifulSoup(res.text)\n",
    "    lng = s.find('lng')\n",
    "    lat = s.find('lat')\n",
    "    \n",
    "    if lng:\n",
    "        return lng.get_text()+','+lat.get_text()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page:1 正在处理\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\li\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file C:\\Users\\li\\Anaconda3\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page:2 正在处理\n",
      "page:3 正在处理\n",
      "90\n"
     ]
    }
   ],
   "source": [
    "# 获取房源信息：小区名称、房价、位置、价格、关注度\n",
    "house_file = open('houseInfo.csv','w',newline='')#存放房源信息，newline=''是为了写入文件时不多出空行\n",
    "writers = csv.DictWriter(house_file,fieldnames=house.keys())\n",
    "writers.writeheader()\n",
    "info_num=0#记录房源信息的总条数\n",
    "\n",
    "#获取房源信息\n",
    "for i in range(1,4):\n",
    "    print('page:%d 正在处理' %(i))\n",
    "    web_url = url + str(i)\n",
    "    soup = BeautifulSoup(requests.get(web_url,headers=headers).content.decode('utf-8'),'html.parser')\n",
    "    houseInfo_tags = soup.find_all(name='div',attrs={'class':'houseInfo'})\n",
    "    housePricce_tags = soup.find_all(name='div',attrs={'class':'totalPrice'})\n",
    "    houseFoc_tags = soup.find_all(name='div',attrs={'class':'followInfo'})\n",
    "    num = len(housePricce_tags)\n",
    "    \n",
    "    for n in range(num):\n",
    "        houseInfo = houseInfo_tags[n].text\n",
    "        houseInfo_list = houseInfo.split('|')\n",
    "        house['name']  = houseInfo_list[0]\n",
    "        house['style'] = re.search('(\\d\\D\\d\\D)|(\\d\\D\\d\\D\\d.)',houseInfo).group()\n",
    "        house['size'] = re.search('\\d+\\.?\\d+',houseInfo).group()\n",
    "        house['price'] = re.search('^\\d+',housePricce_tags[n].text).group()\n",
    "        house['foc'] = re.search('^\\d+',houseFoc_tags[n].text).group()\n",
    "        house['loc'] = getlocation(house['name'])\n",
    "        writers.writerow(house)\n",
    "        info_num += 1\n",
    "\n",
    "print(info_num)\n",
    "house_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从房源信息（houseInfo.csv)提取经纬度信息和房源的关注度信息，为画热力图做数据准备\n",
    "house_file = open('houseInfo.csv','r',newline='') \n",
    "reader = csv.DictReader(house_file)\n",
    "data_file = open('foc_data.txt','w')\n",
    "\n",
    "for i,row in enumerate(reader):\n",
    "    \n",
    "    loc = row['loc'].split(',')\n",
    "    \n",
    "    if len(loc) == 2 and loc[0] != '' and loc[1] != '':\n",
    "        lng = loc[0]\n",
    "        lat = loc[1]\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "    foc = row['foc']\n",
    "    out = '{\\\"lng\\\":'+lng+',\\\"lat\\\":'+lat+',\\\"count\\\":'+foc+'}'\n",
    "    data_file.write(out)\n",
    "    \n",
    "    if i != info_num:\n",
    "        data_file.write(',\\n')\n",
    "            \n",
    "    \n",
    "data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将热力图点的数据填充到热力图模板html中的相应位置\n",
    "file = open('model.html','r',encoding='utf-8',newline='')\n",
    "hot_file = open('house_hot.html','w',encoding='utf-8',newline='')\n",
    "\n",
    "for line in file.readlines():\n",
    "    hot_file.write(line)\n",
    "    \n",
    "    if re.search('var points',line)!=None:\n",
    "        \n",
    "        with open('foc_data.txt','r',encoding='utf-8') as data:\n",
    "            for l in data.readlines():\n",
    "                hot_file.write(\"\\t\")\n",
    "                hot_file.write(l.strip(' '))\n",
    "            hot_file.write(\"\\t];\\n\")\n",
    "            \n",
    "hot_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
